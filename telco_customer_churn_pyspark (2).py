# -*- coding: utf-8 -*-
"""Telco Customer Churn Pyspark.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ROy-2ExMfqSC7s0moH9bAnReiSDSG4t

# Project Brief: Telecom Customer Churn Prediction using PySpark

<h3><b>Background Information</b></h3>
Customer churn is a significant challenge in the telecom industry. Identifying customers who are
likely to churn is crucial for implementing proactive measures to retain them. By leveraging PySpark,
we can take advantage of its distributed computing capabilities to handle large volumes of data
efficiently and build an accurate machine learning model for churn prediction.

## Problem Statement

The goal of this project is to develop a machine learning model using PySpark that <b><i>accurately
predicts customer churn in a telecom company. The model should achieve a minimum accuracy of
0.8,</i></b> enabling the company to proactively identify and retain customers at risk of leaving. By
effectively predicting churn, the company can implement targeted retention strategies, reduce
customer attrition, and improve overall business performance.

## Solution Steps
"""

#install pyspark
!pip install pyspark

## Import the libraries
from pyspark.sql.session import SparkSession
from pyspark import SparkContext
import os
import urllib.request
from pyspark.sql.functions import col
import matplotlib.pyplot as plt
import pyspark.sql.functions as F

from pyspark.ml import Pipeline
from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler, MinMaxScaler

# Create a SparkSession
spark = SparkSession.builder.appName("Churn101").getOrCreate()

# Local file path to save the downloaded CSV file
local_file_path = os.getcwd() + "/telecom_dataset.csv"

#Dataset URL
csv_url = "https://archive.org/download/telecom_dataset/telecom_dataset.csv"

# Download the CSV file
urllib.request.urlretrieve(csv_url, local_file_path)

# Fetch and load dataset: https://archive.org/download/telecom_dataset/telecom_dataset.csv
df = spark.read.csv(local_file_path, header=True)

"""### Initial Data Exploration"""

#Preview df data 
df.show()

#Check df shape
# Number of columns
num_columns = len(df.columns)
print("Number of columns:", num_columns)

# Number of rows
num_rows = df.count()
print("Number of rows:", num_rows)

#View df schema
df.printSchema()

#Do some aggregations ...
#Explore Gender vs Churn stats
# Group the data by Gender and Churn and count the occurrences
gender_churn_counts = df.groupby('Gender', 'Churn').count().toPandas()

# Define the colors for "No" and "Yes"
colors = ['blue', 'orange']

# Plot the bar chart
plt.bar(gender_churn_counts['Gender'], gender_churn_counts['count'], color=['blue', 'orange'])

# Add labels and title
plt.xlabel('Gender')
plt.ylabel('Count')
plt.title('Gender vs Churn')

# Create a legend
legend_labels = ['No', 'Yes']
legend_patches = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]
plt.legend(legend_patches, legend_labels)

# Display the chart
plt.show()

#Explore Age feature
# Extract the Age column as a list
age_values = df.select('Age').rdd.flatMap(lambda x: x).collect()

# Sort the age values in ascending order
age_values.sort()

# Plot the histogram
plt.hist(age_values, bins='auto', edgecolor='black')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age Histogram')
plt.show()

"""### Data Preprocessing"""

#Drop nulls 
# Drop null rows
df = df.na.drop()

# Verify the result
print("Shape of DataFrame: {} rows, {} columns".format(df.count(), len(df.columns)))

#Drop duplicate row entries
df = df.dropDuplicates()

# Verify the result
print("Shape of DataFrame: {} rows, {} columns".format(df.count(), len(df.columns)))

#Cast numeric columns from string type to integer or float
# Convert Age column to integer type
updated_df = df.withColumn("Age", col("Age").cast("integer"))

# Convert MonthlyCharges column to float type
updated_df = updated_df.withColumn("MonthlyCharges", col("MonthlyCharges").cast("float"))

# Convert TotalCharges column to float type
updated_df = updated_df.withColumn("TotalCharges", col("TotalCharges").cast("float"))

#View updated schema
updated_df.printSchema()

"""### Feature Engineering """

#Add Age_group column

# Create a new column 'Age_group' based on 'Age' column
df_with_age_group = updated_df.withColumn(
    'Age_group',
    F.when((F.col('Age') >= 0) & (F.col('Age') < 5), '0-4')
    .when((F.col('Age') >= 5) & (F.col('Age') < 10), '5-9')
    .when((F.col('Age') >= 10) & (F.col('Age') < 15), '10-14')
    .when((F.col('Age') >= 15) & (F.col('Age') < 20), '15-19')
    .when((F.col('Age') >= 20) & (F.col('Age') < 25), '20-24')
    .when((F.col('Age') >= 25) & (F.col('Age') < 30), '25-29')
    .when((F.col('Age') >= 30) & (F.col('Age') < 35), '30-34')
    .when((F.col('Age') >= 35) & (F.col('Age') < 40), '35-39')
    .when((F.col('Age') >= 40) & (F.col('Age') < 45), '40-44')
    .when((F.col('Age') >= 45) & (F.col('Age') < 50), '45-49')
    .when((F.col('Age') >= 50) & (F.col('Age') < 55), '50-54')
    .when((F.col('Age') >= 55) & (F.col('Age') < 60), '55-59')
    .when((F.col('Age') >= 60) & (F.col('Age') < 65), '60-64')
    .otherwise('65+')
)

# Show the updated DataFrame
df_with_age_group.show()

# Add a new column 'Month_Total_Ratio' by dividing 'MonthlyCharges' / 'TotalCharges'
df_with_ratio = df_with_age_group.withColumn(
    'Month_Total_Ratio',
    F.col('MonthlyCharges') / F.col('TotalCharges')
)

# Show the updated DataFrame
df_with_ratio.show()

# Feature Scaling 
# Define the numerical columns
numerical_columns = ['Age', 'MonthlyCharges', 'TotalCharges', 'Month_Total_Ratio']

# Assemble the numerical columns into a vector column
assembler = VectorAssembler(inputCols=numerical_columns, outputCol="vFeatures")

# Create a MinMaxScaler object
scaler = MinMaxScaler(inputCol="vFeatures", outputCol="scaled_features")

#Categorical encoding

catCols = ['Gender', 'Contract', 'Churn', 'Age_group']
indexers = []

# Iterate over the categorical columns
for col in catCols:
    # Create a StringIndexer object, and specify the input and output columns
    stringindexer = StringIndexer(inputCol=col, outputCol=col+"_index")
    indexers.append(stringindexer)

# Create a Pipeline to chain the StringIndexer stages
#-pipeline = Pipeline(stages=indexers)
pipeline = Pipeline(stages=[assembler, scaler] + indexers)

pipeline_model = pipeline.fit(df_with_ratio)
df_encoded = pipeline_model.transform(df_with_ratio)

"""### Model Selection and Training"""

#Feature and Label Target selection

feature_columns = ["scaled_features", "Gender_index", "Contract_index", "Age_group_index"]
label_column = "Churn_index"

# Vectorize Features
vectorAssembler = VectorAssembler(inputCols=feature_columns, outputCol="mainFeatures")
v_data = vectorAssembler.transform(df_encoded)

#Drop columns which are no longer needed
columns_to_drop = ["CustomerID", "Gender", "Age", "Contract", "MonthlyCharges", "TotalCharges", "Churn", "Age_group", "Month_Total_Ratio", "vFeatures", "scaled_features", "Gender_index", "Contract_index", "Age_group_index"]
v_data = v_data.drop(*columns_to_drop)

# Split the Data for Training and Testing
splits = v_data.randomSplit([0.8, 0.2], seed=42)
train_data = splits[0]
test_data = splits[1]

# Verify the result
#train_data.show(truncate=False)
print("Size of Training DataFrame: {} rows".format(train_data.count()))
print("Size of Testing DataFrame: {} rows".format(test_data.count()))
train_data.printSchema()

# Model Selection and Training
lr = LogisticRegression(labelCol="Churn_index", featuresCol="mainFeatures")

# Create a ParamGrid for grid search
param_grid = ParamGridBuilder() \
    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \
    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \
    .build()
		   
# Define the evaluator
evaluator = BinaryClassificationEvaluator(labelCol="Churn_index")

# Create CrossValidator with the LogisticRegression model and BinaryClassificationEvaluator
cross_validator = CrossValidator(estimator=lr,estimatorParamMaps=param_grid,evaluator=evaluator,numFolds=2)  

# Fit the cross-validator to the training data
cvModel = cross_validator.fit(train_data)

# Evaluate the model using the evaluator
accuracy = evaluator.evaluate(cvModel.transform(test_data))

# Get the best model
best_model = cvModel.bestModel

"""### Model Evaluation"""

# Print the best parameters
best_params = best_model.extractParamMap()
print("Best Parameters:")
for param in best_params:
    print(param.name, "=", best_params[param])

# Create a new instance of LogisticRegression
lr_best = LogisticRegression(labelCol="Churn_index", featuresCol="mainFeatures")

# Set the best parameters obtained from the CrossValidator above
lr_best.setParams(aggregationDepth=2,
                  elasticNetParam=0.5,
                  family="auto",
                  fitIntercept=True,
                  maxIter=100,
                  regParam=0.01,
                  standardization=True,
                  threshold=0.5,
                  tol=1e-06)

# Train the logistic regression model with the best parameters
model_best = lr_best.fit(train_data)

# Make predictions on the test data using the best model
predictions_best = model_best.transform(test_data)

# Print model evaluation metrics
evaluator = MulticlassClassificationEvaluator(labelCol="Churn_index")

accuracy_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: "accuracy"})
precision_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: "weightedPrecision"})
recall_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: "weightedRecall"})
f1_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: "f1"})

print("Logistic Regression accuracy:", accuracy_lr)
print("Logistic Regression Precision:", precision_lr)
print("Logistic Regression recall:", recall_lr)
print("Logistic Regression F1-score:", f1_lr)

"""```Success! ...project accuracy level of 0.8 achieved ...```

### Documentation and Reporting

#### Project Findings

Below the model accuracy, precision, recall and F1 scores:

<b><i>Logistic Regression accuracy: 0.8
<br>Logistic Regression Precision: 0.8500000000000001
<br>Logistic Regression recall: 0.8
<br>Logistic Regression F1-score: 0.7809523809523808</i></b>

<i>Project minimum target accuracy of 0.8 was achieved. To improve this score a larger dataset is required to raise model's ability to generalize</i>

#### Challenges

The dataset provided was small. Below some challenges of using small dataset to train the model:

1.<b><i>Risk of overfitting</i></b>:In small datasets, overfitting becomes more likely because the model has fewer examples to learn from. The model may memorize the limited training data instead of capturing meaningful relationships, resulting in poor performance on new data.

2.<b><i>Increased sensitivity to outliers and noise</i></b>: Small datasets are more susceptible to the influence of outliers and noisy data points. An individual outlier can have a disproportionately large impact on the model's training and may lead to misleading results. 

3.<b><i>Limited representation of the underlying population</i></b>: With a small dataset, there is a risk of insufficiently representing the true distribution and variability of the underlying population. This can lead to biased or unreliable models that do not generalize well to unseen data.

#### Lessons Learned

When working with small dataset, the actions below can aid in improving overall model performance:

1.<b><i>Feature engineering</i></b>: Feature engineering involves creating new features better represent the underlying patterns in the data. By carefully selecting and creating informative features, it can enhance the model's ability to capture relevant information even with limited data.

2.<b><i>Cross-validation</i></b>: By partitioning the small dataset into multiple folds, we can train and evaluate the model on different subsets of the data. This allows for a more robust assessment of the model's performance and helps in selecting the best hyperparameters. Caveat! - The more the folds the greater the compute power needed.
"""